"""
Query Log Analyzer

Analyzes JSON query logs generated by QueryDebugger middleware.

Usage:
    python manage.py analyze_queries [log_file] [options]

Options:
    --top N         Show top N endpoints (default: 10)
    --sort-by       Sort by: queries, time, duplicates (default: queries)
    --min-queries   Only show endpoints with at least N queries
    --path          Filter by path pattern
"""

import json
from collections import defaultdict
from django.core.management.base import BaseCommand


class Command(BaseCommand):
    help = 'Analyze query logs from QueryDebugger middleware'

    def add_arguments(self, parser):
        parser.add_argument(
            'log_file',
            type=str,
            help='Path to the JSON log file'
        )
        parser.add_argument(
            '--top',
            type=int,
            default=10,
            help='Show top N endpoints (default: 10)'
        )
        parser.add_argument(
            '--sort-by',
            type=str,
            choices=['queries', 'time', 'duplicates', 'count'],
            default='queries',
            help='Sort by: queries, time, duplicates, count (default: queries)'
        )
        parser.add_argument(
            '--min-queries',
            type=int,
            default=0,
            help='Only show endpoints with at least N queries'
        )
        parser.add_argument(
            '--path',
            type=str,
            default='',
            help='Filter by path pattern'
        )

    def handle(self, *args, **options):
        log_file = options['log_file']
        top_n = options['top']
        sort_by = options['sort_by']
        min_queries = options['min_queries']
        path_filter = options['path']

        # Load and parse logs
        entries = []
        try:
            with open(log_file, 'r') as f:
                for line in f:
                    try:
                        entries.append(json.loads(line.strip()))
                    except json.JSONDecodeError:
                        continue
        except FileNotFoundError:
            self.stderr.write(self.style.ERROR(f'File not found: {log_file}'))
            return

        if not entries:
            self.stderr.write(self.style.WARNING('No log entries found'))
            return

        # Filter by path
        if path_filter:
            entries = [e for e in entries if path_filter in e.get('path', '')]

        # Aggregate by endpoint
        endpoints = defaultdict(lambda: {
            'count': 0,
            'total_queries': 0,
            'total_time': 0,
            'total_query_time': 0,
            'total_duplicates': 0,
            'total_slow': 0,
            'max_queries': 0,
            'tables': defaultdict(int),
        })

        for entry in entries:
            path = entry.get('path', 'unknown')
            method = entry.get('method', 'GET')
            key = f"{method} {path}"

            endpoints[key]['count'] += 1
            endpoints[key]['total_queries'] += entry.get('query_count', 0)
            endpoints[key]['total_time'] += entry.get('elapsed_time', 0)
            endpoints[key]['total_query_time'] += entry.get('query_time', 0)
            endpoints[key]['total_duplicates'] += entry.get('duplicate_count', 0)
            endpoints[key]['total_slow'] += entry.get('slow_query_count', 0)
            endpoints[key]['max_queries'] = max(
                endpoints[key]['max_queries'],
                entry.get('query_count', 0)
            )

            for table, count in entry.get('tables_accessed', {}).items():
                endpoints[key]['tables'][table] += count

        # Calculate averages
        for key, data in endpoints.items():
            data['avg_queries'] = data['total_queries'] / data['count']
            data['avg_time'] = data['total_time'] / data['count']
            data['avg_query_time'] = data['total_query_time'] / data['count']

        # Filter by min queries
        if min_queries > 0:
            endpoints = {
                k: v for k, v in endpoints.items()
                if v['avg_queries'] >= min_queries
            }

        # Sort
        sort_keys = {
            'queries': lambda x: x[1]['avg_queries'],
            'time': lambda x: x[1]['avg_time'],
            'duplicates': lambda x: x[1]['total_duplicates'],
            'count': lambda x: x[1]['count'],
        }
        sorted_endpoints = sorted(
            endpoints.items(),
            key=sort_keys[sort_by],
            reverse=True
        )[:top_n]

        # Output
        self.stdout.write('')
        self.stdout.write(self.style.SUCCESS('=' * 80))
        self.stdout.write(self.style.SUCCESS(' QUERY LOG ANALYSIS'))
        self.stdout.write(self.style.SUCCESS('=' * 80))
        self.stdout.write('')
        self.stdout.write(f'  Log file: {log_file}')
        self.stdout.write(f'  Total entries: {len(entries)}')
        self.stdout.write(f'  Unique endpoints: {len(endpoints)}')
        self.stdout.write(f'  Sorted by: {sort_by}')
        self.stdout.write('')

        # Summary table
        self.stdout.write(self.style.SUCCESS('-' * 80))
        self.stdout.write(
            f'  {"Endpoint":<40} {"Calls":>6} {"Avg Q":>7} {"Max Q":>6} '
            f'{"Avg Time":>9} {"Dups":>5}'
        )
        self.stdout.write(self.style.SUCCESS('-' * 80))

        for endpoint, data in sorted_endpoints:
            # Truncate endpoint name
            endpoint_short = endpoint[:38] + '..' if len(endpoint) > 40 else endpoint

            # Color code by severity
            avg_queries = data['avg_queries']
            if avg_queries > 20:
                style = self.style.ERROR
            elif avg_queries > 10:
                style = self.style.WARNING
            else:
                style = self.style.SUCCESS

            self.stdout.write(style(
                f'  {endpoint_short:<40} {data["count"]:>6} {avg_queries:>7.1f} '
                f'{data["max_queries"]:>6} {data["avg_time"]:>8.3f}s '
                f'{data["total_duplicates"]:>5}'
            ))

        self.stdout.write(self.style.SUCCESS('-' * 80))
        self.stdout.write('')

        # Detailed view for top problematic endpoints
        self.stdout.write(self.style.SUCCESS('TOP PROBLEMATIC ENDPOINTS (Details):'))
        self.stdout.write('')

        for endpoint, data in sorted_endpoints[:3]:
            self.stdout.write(self.style.WARNING(f'  üìç {endpoint}'))
            self.stdout.write(f'     Calls: {data["count"]}')
            self.stdout.write(f'     Avg Queries: {data["avg_queries"]:.1f}')
            self.stdout.write(f'     Max Queries: {data["max_queries"]}')
            self.stdout.write(f'     Avg Time: {data["avg_time"]:.3f}s')
            self.stdout.write(f'     Query Time: {data["avg_query_time"]:.3f}s')
            self.stdout.write(f'     Duplicate Patterns: {data["total_duplicates"]}')
            self.stdout.write(f'     Slow Queries: {data["total_slow"]}')

            if data['tables']:
                top_tables = sorted(
                    data['tables'].items(),
                    key=lambda x: x[1],
                    reverse=True
                )[:5]
                self.stdout.write(f'     Top Tables: {", ".join(f"{t}({c})" for t, c in top_tables)}')

            self.stdout.write('')

        self.stdout.write(self.style.SUCCESS('=' * 80))
